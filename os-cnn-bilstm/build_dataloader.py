import os
import torch
import numpy as np
import pandas as pd
from torch.utils.data import Dataset, DataLoader
from sklearn.model_selection import train_test_split
from GloVe.glove import GloVeEmbeddings

# 数据集文件路径
base_dir = os.path.join('data')

class BuildDataset(Dataset):
    def __init__(self, train=True,sequence_max_len = 50, data_path=""):
        self.data_path = os.path.join(base_dir, data_path)
        self.sequence_max_len = sequence_max_len
        self.glove = GloVeEmbeddings(data_path.split("/")[0])
        self.df = pd.read_csv(self.data_path)

        train_df, test_df = train_test_split(self.df, test_size=0.1, random_state=42)
        if train:
            self.df = train_df
        else:
            self.df = test_df
    
    def __getitem__(self, index):
        
        api_list = tokenlize(self.df.iloc[index]['api_low'])
        label = self.df.iloc[index]['label']

        api_idx_list = self.glove.word2idx(api_list, self.sequence_max_len)
        api_vector_list = self.glove.idx2vector(api_idx_list)

        return api_idx_list, api_vector_list, label
    
    def __len__(self):
        return len(self.df)


def tokenlize(sentence):
    """
    进行文本分词
    :param sentence: strs
    :return: [str,str,str]
    """
    # fileters = ['!', '"', '#', '$', '%', '&', '\(', '\)', '\*', '\+', ',', '-', '\.', '/', ':', ';', '<', '=', '>',
    #             '\?', '@', '\[', '\\', '\]', '^', '_', '`', '\{', '\|', '\}', '~', '\t', '\n', '\x97', '\x96', '”',
    #             '“', ]
    # sentence = sentence.lower()  # 把大写转化为小写
    # sentence = re.sub("<br />", " ", sentence)
    # sentence = re.sub("|".join(fileters), " ", sentence)
    result = [i for i in sentence.split(" ") if len(i) > 0]

    return result

def collate_fn(batch):
    api_idx_list, api_vector_list, label = zip(*batch)
    
    # return torch.tensor(api_vector_list,dtype=torch.float32), torch.tensor(label,dtype=torch.float32)
    return torch.tensor(np.array(api_idx_list),dtype=torch.float32), torch.tensor(np.array(api_vector_list),dtype=torch.float32), torch.tensor(np.array(label))

def BuildDataloader(batch_size, sequence_max_len, data_path):
    train_dataset = BuildDataset(train=True, sequence_max_len=sequence_max_len, data_path=data_path)
    train_dataloader = DataLoader(train_dataset, batch_size=batch_size,collate_fn=collate_fn)

    test_dataset = BuildDataset(train=False, sequence_max_len=sequence_max_len, data_path=data_path)
    test_dataloader = DataLoader(test_dataset, batch_size=batch_size,collate_fn=collate_fn)

    return train_dataloader, test_dataloader
